{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "$$y \\sim N(X\\beta, \\sigma^2) $$\n",
    "$$\\hat{\\beta} = argmin_{\\beta} ||Y - X\\beta||^2$$\n",
    "\n",
    "**Questions**:\n",
    "    \n",
    "1. What are the assumptions for linear regression\n",
    "2. What is the consistent estimator for $\\beta$ and $\\sigma^2$\n",
    "    \n",
    "**Practice**:\n",
    "    \n",
    "1. Generate a dataset $X\\sim N(0, 1)$, with 300 observations, dimensions is 3.   \n",
    "    Use `numpy.random.randn` or call `np.random.randn`. [More distributions](https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html)\n",
    "2. Set $\\beta = (1, 2, 3)$ and set $\\sigma^2 = 1$\n",
    "3. Generate $y \\sim N(X\\beta, \\sigma^2)$\n",
    "4. Create a function `lm`, and give the estimates $\\hat{\\beta}_{lm}$, $var(\\hat{\\beta}_{lm})$ and $\\hat{\\sigma}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, P = 300, 3 # dimension information\n",
    "x = np.random.randn(N, P) # X from standard normal distribution\n",
    "beta = np.array([1, 2, 3]) # Create beta\n",
    "sigma = 1\n",
    "y = x @ beta + np.random.randn(N) * sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Def a function, here the indent is import for both \n",
    "def lm(x, y):\n",
    "    n, p = x.shape\n",
    "    beta = np.linalg.inv((x.T @ x)) @ x.T @ y\n",
    "    yhat = x @ beta\n",
    "    residuals = y - yhat\n",
    "    sse = residuals.transpose() @ residuals\n",
    "    sigma = sse / (n - p)\n",
    "    return beta, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hat, sigma_hat = lm(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression result.\n",
      "Beta: [1.07231236 1.9909473  3.05035161]\n",
      "Sigma: 0.9815952841809558\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear regression result.\\n\\\n",
    "Beta: {}\\n\\\n",
    "Sigma: {}\".format(beta_hat, sigma_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PRACTICE**\n",
    "\n",
    "**Questions**:\n",
    "\n",
    "\n",
    "1. If you have too many predictors, what are the problems? **Multiple Collinearity**\n",
    "2. How do you solve it? List at least 3 methods. **Ridge, PCA, Panelization**\n",
    "3. What are the properties these methods? \n",
    "\n",
    "**Programming**:\n",
    "\n",
    "1. Implement a function ridge, which is used to solve ridge regression problem\n",
    "\n",
    "$$\\hat{\\beta}_{ridge} = argmin_{\\beta} ||Y - X\\beta||^2 + \\lambda ||\\beta||^2$$\n",
    "\n",
    "2. Give the estimates of $\\hat{\\beta}_{ridge}$ and $var(\\hat{\\beta}_{ridge})$\n",
    "3. Consider what is the relationship between $\\beta_{lm}$ and $\\beta_{ridge}$\n",
    "4. How about if $X'X$ is an orthogonal matrix?\n",
    "5. What is the equivalent Bayesian formulation? **TALKED**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(x, y, lamb):\n",
    "    n, p = x.shape\n",
    "    XtX = x.transpose() @ x\n",
    "    lambInv = np.linalg.inv(lamb * np.eye(p) + XtX)\n",
    "    beta_hat = lambInv @ x.T @ y\n",
    "    yhat = x @ beta\n",
    "    residuals = y - yhat\n",
    "    sse = residuals.transpose() @ residuals\n",
    "    sigma = sse / (n - p)\n",
    "    beta_se = np.diag(sse * lambInv @ XtX @ lambInv)\n",
    "    return beta_hat, sigma, beta_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hat, sigma_hat, beta_se = ridge(x, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear ridge regression result.\n",
      "\n",
      "Beta: [1.06811645 1.98403775 3.04090018]\n",
      "Beta SE: [1.02283538 1.13387332 0.89922683]\n",
      "Sigma: 0.9886532419196511\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear ridge regression result.\\n\\n\\\n",
    "Beta: {}\\n\\\n",
    "Beta SE: {}\\n\\\n",
    "Sigma: {}\".format(beta_hat, beta_se, sigma_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
